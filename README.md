<!-- TOC -->
  * [1. äº‹ä»¶èµ·å› ](#1-äº‹ä»¶èµ·å› )
    * [1.1 æ€§èƒ½æµ‹è¯•](#11-æ€§èƒ½æµ‹è¯•)
    * [1.2 std::shared_mutex](#12-stdshared_mutex)
    * [1.3 clang::shared_mutex](#13-clangshared_mutex)
    * [1.4 DB::SharedMutex](#14-dbsharedmutex)
  * [2. Futex](#2-futex)
  * [3. ä¸åŒè¯»å†™é”å®ç°æ¢ç´¢](#3-ä¸åŒè¯»å†™é”å®ç°æ¢ç´¢)
    * [3.1 std::shared_mutex(gcc)](#31-stdshared_mutexgcc)
    * [3.2 clang::shared_mutex](#32-clangshared_mutex)
    * [3.3 DB::SharedMutex](#33-dbsharedmutex)
      * [3.3.1 ğŸ“œÂ `state`Â å˜é‡çš„ä½å¸ƒå±€](#331-stateå˜é‡çš„ä½å¸ƒå±€)
      * [3.3.2 ğŸ”‘ å…³é”®å®ç°æœºåˆ¶](#332--å…³é”®å®ç°æœºåˆ¶)
        * [1ï¸âƒ£ â€‹ **è°ƒç”¨ Futex å®Œæˆç­‰å¾…å”¤é†’**â€‹](#1--è°ƒç”¨-futex-å®Œæˆç­‰å¾…å”¤é†’)
        * [2ï¸âƒ£ â€‹**å†™é”è·å– (`lock()`)â€‹**â€‹](#2-å†™é”è·å–-lock)
        * [3ï¸âƒ£ â€‹**è¯»é”è·å– (`lock_shared()`)â€‹**â€‹](#3-è¯»é”è·å–-lock_shared)
        * [4ï¸âƒ£ â€‹**è§£é”ä¼˜åŒ–ç­–ç•¥**â€‹](#4-è§£é”ä¼˜åŒ–ç­–ç•¥)
        * [5ï¸âƒ£ â€‹**ç«¯åºå…¼å®¹å¤„ç†**â€‹](#5-ç«¯åºå…¼å®¹å¤„ç†)
    * [3.4 pthread_rwlock](#34-pthread_rwlock)
      * [3.4.1 æ€»ä½“è®¾è®¡æè¿°](#341-æ€»ä½“è®¾è®¡æè¿°)
        * [æ ¸å¿ƒè®¾è®¡ç›®æ ‡](#æ ¸å¿ƒè®¾è®¡ç›®æ ‡)
        * [æ ¸å¿ƒçŠ¶æ€æœºï¼ˆåŸºäºÂ `__readers`Â å­—æ®µï¼‰](#æ ¸å¿ƒçŠ¶æ€æœºåŸºäº__readerså­—æ®µ)
          * [çŠ¶æ€è¡¨](#çŠ¶æ€è¡¨)
          * [å…³é”®çŠ¶æ€è½¬ç§»](#å…³é”®çŠ¶æ€è½¬ç§»)
        * [Futex åŒæ­¥æœºåˆ¶](#futex-åŒæ­¥æœºåˆ¶)
          * [ä¼˜åŒ–ï¼šé¿å…æ— æ•ˆ Futex è°ƒç”¨](#ä¼˜åŒ–é¿å…æ— æ•ˆ-futex-è°ƒç”¨)
        * [å†…å­˜é¡ºåºï¼ˆMemory Orderingï¼‰](#å†…å­˜é¡ºåºmemory-ordering)
        * [å…¶ä»–è®¾è®¡è¦ç‚¹](#å…¶ä»–è®¾è®¡è¦ç‚¹)
        * [æœ¯è¯­è¡¨](#æœ¯è¯­è¡¨)
      * [3.4.2 å¦‚ä½•å®ç°è¯»ä¼˜å…ˆå’Œå†™ä¼˜å…ˆ](#342-å¦‚ä½•å®ç°è¯»ä¼˜å…ˆå’Œå†™ä¼˜å…ˆ)
        * [â€‹**å†™è€…ä¼˜å…ˆç­–ç•¥å®ç°**â€‹ï¼ˆPTHREAD_RWLOCK_PREFER_WRITER_NONRECURSIVE_NPï¼‰](#å†™è€…ä¼˜å…ˆç­–ç•¥å®ç°pthread_rwlock_prefer_writer_nonrecursive_np)
        * [â€‹**è¯»è€…ä¼˜å…ˆç­–ç•¥å®ç°**â€‹ï¼ˆPTHREAD_RWLOCK_PREFER_READER_NPï¼‰](#è¯»è€…ä¼˜å…ˆç­–ç•¥å®ç°pthread_rwlock_prefer_reader_np)
        * [â€‹**å…³é”®ç§»äº¤æœºåˆ¶**â€‹ï¼ˆä¸¤è€…é€šç”¨ï¼‰](#å…³é”®ç§»äº¤æœºåˆ¶ä¸¤è€…é€šç”¨)
        * [ç­–ç•¥å¯¹æ¯”æ‘˜è¦](#ç­–ç•¥å¯¹æ¯”æ‘˜è¦)
<!-- TOC -->

## 1. äº‹ä»¶èµ·å› 

åœ¨ clickhouse æºç ä¸­å‘ç°ä»–è‡ªå·±å®ç°äº† [DB::SharedMutex](https://github.com/ClickHouse/ClickHouse/blob/371c7c2e023218b5004a55f1084adb400e8ab64e/src/Common/SharedMutex.h#L15-L43)ï¼Œè€Œåœ¨é Linux ç¯å¢ƒæ‰ä½¿ç”¨æ ‡å‡†åº“çš„ `std::shared_mutex`ï¼ˆåˆšåˆšæŸ¥çœ‹æœ€æ–°åˆ†æ”¯ä»£ç å‘ç°é Linux ä¸‹ä¹Ÿä½¿ç”¨çš„ absl çš„å®ç°ï¼‰ã€‚è€Œå…¶ä¸­è‡ªå®ç°çš„è¯»å†™é”ä½¿ç”¨ futexï¼ˆlinuxç‰¹æœ‰çš„APIï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªæˆ‘ä¹‹å‰ä»æœªå¬è¿‡çš„åè¯ï¼Œæˆ‘å¯¹ futex ä»¥åŠæ ‡å‡†åº“çš„ shared_mutex çœŸçš„æ€§èƒ½è¿™ä¹ˆå·®å—ï¼Ÿæ„Ÿåˆ°éå¸¸çš„å¥½å¥‡ã€‚äºæ˜¯ä¾¿æœ‰äº†æœ¬ç¯‡æ–‡ç« ã€‚

æœ‰å…³ futex æ˜¯ä¸ªä»€ä¹ˆï¼Ÿå…¶å…¨ç§°æ˜¯ Fast Userspace Mutexï¼Œå¾ˆæ˜æ˜¾æ˜¯å‡å°‘å†…æ ¸é™·å…¥æ¬¡æ•°çš„åŒæ­¥å·¥å…·ï¼Œå…·ä½“ç»†èŠ‚è¯·æŸ¥çœ‹ [Futex](#Futex) ã€‚

æ ‡å‡†åº“ shared_mutex çš„æ€§èƒ½çœŸçš„æœ‰é‚£ä¹ˆå·®å—ï¼Ÿ

### 1.1 æ€§èƒ½æµ‹è¯•

è¿™æ˜¯æˆ‘å®é™…æµ‹è¯•çš„å¯¹æ¯”æƒ…å†µï¼ˆæœºå™¨æ˜¯32æ ¸ï¼Œlinux 6.6.80 glibc2.38ï¼Œå‡ä½¿ç”¨ clang-19 -O3 ç¼–è¯‘ï¼‰ï¼š
æµ‹è¯•ä»£ç ï¼š [source](https://github.com/acking-you/test_shared_mutex/blob/main/main.cpp)

| â€‹**åœºæ™¯**â€‹      | â€‹**std::shared_mutex**â€‹ | â€‹**clang::shared_mutex**â€‹ | â€‹**DB::SharedMutex**â€‹ | â€‹**æ€§èƒ½é¢†å…ˆæ–¹**â€‹        |
| ------------- | ----------------------- | ------------------------- | --------------------- | ------------------ |
| â€‹**64è¯», 0å†™**â€‹ | 2,842,706               | 1,270,939                 | â€‹**3,047,856**â€‹       | ğŸŸ¢ â€‹**DBé«˜7.2%â€‹**â€‹  |
| â€‹**0è¯», 64å†™**â€‹ | 29,297                  | 28,479                    | â€‹**31,901**â€‹          | ğŸŸ¢ â€‹**DBé«˜8.9%â€‹**â€‹  |
| â€‹**64è¯», 16å†™** | â€‹**3,028,239**â€‹         | 730,139                   | 122,343               | ğŸŸ¡ â€‹**stdé«˜24.7å€**â€‹ |
| â€‹**16è¯», 64å†™** | â€‹**1,549,032**â€‹         | 73,387                    | 34,014                | ğŸŸ¡ â€‹**stdé«˜45.5å€**â€‹ |
| â€‹**64è¯», 1å†™**â€‹ | â€‹**3,029,552**â€‹         | 771,498                   | 3,027,012             | âš–ï¸ â€‹**stdä¸DBæŒå¹³**â€‹  |
| â€‹**1è¯», 64å†™**â€‹ | 30,617                  | 29,291                    | â€‹**31,969**â€‹          | ğŸŸ¢ â€‹**DBé«˜4.4%â€‹**â€‹  |

æˆ‘æœ¬æ¥æ˜¯åªæµ‹äº†æ ‡å‡†åº“ä¸­çš„å®ç°å’Œ ClickHouse ä¸­çš„ DB::SharedMutexï¼Œä½†æµ‹ä¸‹æ¥å‘ç°æ€§èƒ½åè€Œæ˜¯æ ‡å‡†åº“çš„æ›´å¥½ï¼Œæˆ‘è®°å¾—æˆ‘çœ‹è¿‡ clang çš„ libcxx å®ç°ï¼Œå°±æ˜¯ä¸€ä¸ª mutex+ä¸¤ä¸ª cv +ä¸€ä¸ª state å˜é‡æ¥å®ç°ï¼ŒæŒ‰ç†æ¥è¯´åº”è¯¥æ˜¯ä¸å¯èƒ½æ¯”ç›´æ¥åŸºäº futex+atomic çš„ DB::SharedMutex è¦å¥½å•Šã€‚äºæ˜¯æˆ‘æŸ¥çœ‹è¯¥é¡¹ç›®ç´¢å¼•åˆ°çš„ `std::shared_mutex` å®ç°ï¼Œå‘ç°ä¸å¯¹åŠ²ï¼Œæ€ä¹ˆåˆ°äº† gcc çš„ libcxx å®ç°äº†ï¼Ÿï¼ˆæˆ‘æ˜æ˜ç”¨çš„ llvm19 toolchainï¼Œå‘ç°æ˜¯åœ¨ llvm é‚£ä¸ªç›®å½•ä¸‹æ—¢æœ‰ clangåˆæœ‰ gcc çš„ libcxxï¼‰

è€Œ gcc çš„ `std::shared_mutex` å®ç°å¦‚ä¸‹ï¼š
```cpp
#if _GLIBCXX_USE_PTHREAD_RWLOCK_T
    typedef void* native_handle_type;
    native_handle_type native_handle() { return _M_impl.native_handle(); }

  private:
    __shared_mutex_pthread _M_impl;
#else
  private:
    __shared_mutex_cv _M_impl;
#endif
  };
#endif // __cpp_lib_shared_mutex
```

åœ¨ Linux ä¸‹é»˜è®¤ä¼šä½¿ç”¨ pthread_rwlock ï¼Œè€Œä¸æ˜¯å¦ä¸€ä¸ªåŸºäº cv å®ç°çš„ç‰ˆæœ¬ã€‚

è™½ç„¶ä¸çŸ¥é“åŸºäºä»€ä¹ˆåŸå› ï¼Œæˆ‘è¿™ä¸ªåŸºäº llvm toolchain çš„é¡¹ç›®ä½¿ç”¨çš„æ˜¯ gcc çš„ libcxxï¼Œä½†ä¸å¦¨ç¢æˆ‘æ¨¡æ‹Ÿ clang libcxx çš„å®ç°ï¼ˆç›´æ¥æ‰¾åˆ° [llvm-project](https://github.com/llvm/llvm-project/blob/main/libcxx/include/shared_mutex#L156-L210) çš„æºç å³å¯ï¼‰ã€‚
ç”±äºç›´æ¥ copy å¯¹åº”çš„æ–‡ä»¶ä¾èµ–çš„å¤´æ–‡ä»¶å¤ªå¤šäº†ï¼Œäºæ˜¯ç›´æ¥è®© ai æŸ¥çœ‹æºç é€»è¾‘ç”Ÿæˆäº†ä¸€ä¸ªä¸€æ ·çš„å®ç°ï¼Œä¹Ÿæ”¾åœ¨æµ‹è¯•æºç çš„ä»“åº“ä¸­ï¼Œæµ‹è¯•ç»“æœå°±æ˜¯ä¸Šè¡¨ä¸­çš„ `clang::shared_mutex`ã€‚

æœç„¶ clang libcxx çš„å®ç°æ€§èƒ½æ˜¯æœ€å·®çš„ã€‚ä½†æˆ‘ä¹Ÿè¿˜æ˜¯å¯¹ä¸ºä»€ä¹ˆ ClickHouse çš„å®ç°æ‰“ä¸è¿‡ pthread_rwlock æ„Ÿåˆ°å¥½å¥‡ï¼Œå½“ç„¶ä¹Ÿä¸æ˜¯å®Œå…¨æ‰“ä¸è¿‡ï¼Œæ˜¯åœ¨æœ‰ä¸€äº›å†™æ“ä½œçš„æ—¶å€™ä¼šååé‡ä¼šè½åï¼Œè¯»æ“ä½œè¿œå¤§äºå†™æ“ä½œçš„æ—¶å€™æ€§èƒ½ä¼šæ›´å¥½ã€‚

æˆ‘æ€€ç–‘åŸå› å¦‚ä¸‹ï¼š
1. pthread_rwlock æ˜¯è¯»è€…ä¼˜å…ˆçš„ï¼ˆäº‹å®è¯æ˜åˆ†ææ˜¯æ­£ç¡®çš„ï¼Œè¯¦ç»†è§ä¸‹æ–‡çš„æ¢ç´¢ï¼‰ï¼Œæ‰€ä»¥èƒ½åšåˆ°ååé‡å¾ˆé«˜ï¼ˆæœ¬æµ‹è¯•è®¾è®¡çš„æ˜¯å†™æ“ä½œæ˜¯è¯»æ“ä½œçš„ä¸‰å€è€—æ—¶
2. è€Œ `DB::SharedLock` åˆ™å†™è€…ä¼˜å…ˆï¼Œè‹¥æœ‰å†™è€…ç­‰å¾…åˆ™ä¼šä½¿å¾—è¯»è€…ä¹Ÿé™·å…¥ç­‰å¾…ï¼Œè€Œæ­¤æ—¶è¯»é”ä¸€æ—¦é‡Šæ”¾æ ¹æ®åˆ¤æ–­æ¡ä»¶åªä¼šå”¤é†’å†™è€…ã€‚

æ¯”è¾ƒæœ‰æ„æ€çš„æ˜¯ï¼Œä¹Ÿè®¸æ˜¯å‘ç°ç›®å‰çš„å®ç°æ€§èƒ½éå¸¸å·® clang çš„ libcxx æœ‰ä¸ª PR å°±æ˜¯æ”¯æŒåŸºäº `pthread_rwlock_t` çš„ `std::shared_mutex`ï¼š https://github.com/llvm/llvm-project/pull/148046 ï¼Œä¹‹å‰çš„å®ç°ä¼°è®¡è€ƒè™‘åˆ°æ ‡å‡†åº“çš„è·¨å¹³å°ï¼Œæ‰€ä»¥ç®€å•çš„åŸºäºç°æœ‰çš„ cv å®ç°ã€‚

è¯¦ç»†æµ‹è¯•ç»“æœè¯·çœ‹ä¸‹é¢çš„å†…å®¹ã€‚
### 1.2 std::shared_mutex

| åœºæ™¯       | æ€»æ“ä½œæ•°      | è¯»æ“ä½œæ•°      | å†™æ“ä½œæ•°   | è€—æ—¶(ms) | ååé‡(op/s) |
| -------- | --------- | --------- | ------ | ------ | --------- |
| 64è¯», 0å†™  | 5,696,782 | 5,696,782 | 0      | 2004   | 2,842,706 |
| 0è¯», 64å†™  | 58,681    | 0         | 58,681 | 2003   | 29,297    |
| 64è¯», 16å†™ | 6,080,703 | 6,080,687 | 16     | 2008   | 3,028,239 |
| 16è¯», 64å†™ | 3,102,712 | 3,102,647 | 65     | 2003   | 1,549,032 |
| 64è¯», 1å†™  | 6,089,400 | 6,089,399 | 1      | 2010   | 3,029,552 |
| 1è¯», 64å†™  | 61,326    | 30,631    | 30,695 | 2003   | 30,617    |

### 1.3 clang::shared_mutex

| åœºæ™¯       | æ€»æ“ä½œæ•°      | è¯»æ“ä½œæ•°      | å†™æ“ä½œæ•°   | è€—æ—¶(ms) | ååé‡(op/s) |
| -------- | --------- | --------- | ------ | ------ | --------- |
| 64è¯», 0å†™  | 2,543,149 | 2,543,149 | 0      | 2001   | 1,270,939 |
| 0è¯», 64å†™  | 56,986    | 0         | 56,986 | 2001   | 28,479    |
| 64è¯», 16å†™ | 1,461,009 | 1,451,015 | 9,994  | 2001   | 730,139   |
| 16è¯», 64å†™ | 146,848   | 105,522   | 41,326 | 2001   | 73,387    |
| 64è¯», 1å†™  | 1,543,768 | 1,538,093 | 5,675  | 2001   | 771,498   |
| 1è¯», 64å†™  | 58,611    | 3,028     | 55,583 | 2001   | 29,291    |

### 1.4 DB::SharedMutex

| åœºæ™¯       | æ€»æ“ä½œæ•°      | è¯»æ“ä½œæ•°      | å†™æ“ä½œæ•°   | è€—æ—¶(ms) | ååé‡(op/s) |
| -------- | --------- | --------- | ------ | ------ | --------- |
| 64è¯», 0å†™  | 6,123,143 | 6,123,143 | 0      | 2009   | 3,047,856 |
| 0è¯», 64å†™  | 63,865    | 0         | 63,865 | 2002   | 31,901    |
| 64è¯», 16å†™ | 244,809   | 210,495   | 34,314 | 2001   | 122,343   |
| 16è¯», 64å†™ | 68,131    | 13,733    | 54,398 | 2003   | 34,014    |
| 64è¯», 1å†™  | 6,054,023 | 6,053,701 | 322    | 2000   | 3,027,012 |
| 1è¯», 64å†™  | 64,002    | 1,024     | 62,978 | 2002   | 31,969    |

## 2. Futex

ç”±äºå‰é¢çš„ benchmarkï¼Œä½¿å¾—æˆ‘å¯¹ `pthread_rwlock` è¿™ä¸ª libc è°ƒç”¨éå¸¸å¥½å¥‡ï¼Œäºæ˜¯æŸ¥çœ‹äº†ç›¸å…³çš„æºç å˜åŠ¨ï¼Œå‘ç°å…¶å‡ ä¹ä»æœ€åŸå§‹çš„ glibc ç‰ˆæœ¬å°±å·²ç»ä½¿ç”¨äº† futex ã€‚

Futexæ˜¯ä¸€ç§ç”¨æˆ·æ€å’Œå†…æ ¸æ€æ··åˆçš„åŒæ­¥æœºåˆ¶ï¼Œé€šè¿‡åœ¨ç”¨æˆ·ç©ºé—´ä¸­å­˜å…¥ä¸€ä¸ª futex çŠ¶æ€å˜é‡ï¼Œå½“çº¿ç¨‹æˆ–è¿›ç¨‹ï¼ˆéœ€è¦é€šè¿‡ mmap å…±äº« futex å†…å­˜ï¼‰å°è¯•è¿›å…¥äº’æ–¥åŒºæˆ–è€…é€€å‡ºäº’æ–¥åŒºçš„æ—¶å€™ï¼Œ1. å…ˆå»æŸ¥çœ‹å…±äº«å†…å­˜ä¸­çš„futexå˜é‡ï¼ˆåŸå­æ“ä½œ CASï¼‰ï¼Œå¦‚æœæ²¡æœ‰ç«äº‰å‘ç”Ÿï¼Œåˆ™åªä¿®æ”¹futexï¼Œè€Œä¸ç”¨å†é™·å…¥å†…æ ¸ç­‰å¾…ã€‚ 2.ä»…å½“é€šè¿‡è®¿é—®futexå˜é‡å‘Šè¯‰è¿›ç¨‹æœ‰ç«äº‰å‘ç”Ÿæ—¶ï¼Œæ‰æ‰§è¡Œç³»ç»Ÿè°ƒç”¨å»å®Œæˆç›¸åº”çš„å¤„ç†ã€‚

ä¸ä¸Šè¿°èƒ½åŠ›æœ‰å…³çš„è°ƒç”¨å°±ä¸‹é¢ä¸¤ä¸ªï¼š
```
// futex_word æŒ‡å‘futexçŠ¶æ€å˜é‡ï¼Œexpcted ä»£è¡¨è¿™ä¸ªåœ°å€æœŸå¾…çš„å€¼ï¼Œå½“*futex_word==expected æ—¶ï¼Œæ‰ä¼šè¿›è¡Œwait
int futex_wait (unsigned int *futex_word, unsigned int expected, int private);


// å”¤é†’ processes_to_wake ä¸ªåœ¨ futex_word æŒ‡å‘çš„é”å˜é‡ä¸ŠæŒ‚èµ·ç­‰å¾…çš„è¿›ç¨‹
void futex_wake (unsigned int* futex_word, int processes_to_wake, int private);

// ä¸Šè¿° private å­—æ®µä¸å…±äº«å†…å­˜æœ‰å…³ï¼Œå¯ä»¥æŸ¥çœ‹ç›¸å…³æºç æ³¨é‡Š
```


æœ‰å…³ glibc çš„ futex è¯¦ç»†å®ç°ä»‹ç»å¯ä»¥æŸ¥çœ‹è¿™ä¸ªæ³¨é‡Š [glibc-2.22](https://elixir.bootlin.com/glibc/glibc-2.22/source/sysdeps/nptl/futex-internal.h#L28-L66)ã€‚

æ ¹æ® glibc 2.22 çš„ changelog å¯çŸ¥ç»Ÿä¸€äº†glibc å†…éƒ¨ä½¿ç”¨çš„futexesåœ¨ä¸Šè¿°é“¾æ¥çš„æ–‡ä»¶ä¸­ã€‚
```
* Handle private futexes in the NPTL implementation.
  Implemented by Jakub Jelinek and Ulrich Drepper.
```

è€Œ glibc å®é™…å¹¶ä¸æš´éœ² futex çš„ wrapper ä¾›ç”¨æˆ·ä½¿ç”¨ï¼Œå¯ä»¥æŸ¥çœ‹ man æ–‡æ¡£ï¼Œé€šè¿‡ syscall å®Œæˆè°ƒç”¨ï¼š https://man7.org/linux/man-pages/man2/futex.2.html

æœ‰å…³ futex è°ƒç”¨çš„å…·ä½“å®è·µï¼Œå¯ä»¥æŸ¥çœ‹ `DB::SharedMutex` ä¸€èŠ‚ä¸­çš„ä»£ç å®ç°ã€‚

ä¸ºä»€ä¹ˆéœ€è¦ä¸“é—¨çš„ futex åŸè¯­ï¼Œè€Œä¸æ˜¯è®©å¼€å‘è€…æ‰‹åŠ¨ç»„åˆåŸå­æ“ä½œå’Œç³»ç»Ÿè°ƒç”¨ï¼Ÿ

ä¸‹é¢æ˜¯ deepseek çš„å›ç­”ï¼š
åŸå­æ€§ç¼ºå£ï¼šå†…æ ¸æ€æ— æ³•ä¿éšœçš„ç”¨æˆ·æ€æ£€æŸ¥
â€‹**è‡´å‘½çš„æ—¶é—´çª—é—®é¢˜ï¼šâ€‹**â€‹

```mermaid
sequenceDiagram
    User->User: CASæ£€æŸ¥(å¤±è´¥)
    User->Kernel: sys_nanosleep()è¯·æ±‚ä¼‘çœ 
    Note right of Kernel: åœ¨æ­¤é—´éš™
    OtherThread->Lock: é‡Šæ”¾é”
    OtherThread->User: å°è¯•å”¤é†’(ä½†ç›®æ ‡æœªä¼‘çœ !)
    Kernel->User: è¿›å…¥ä¼‘çœ 
```

- â€‹**é—®é¢˜**â€‹ï¼šåœ¨ CAS å¤±è´¥åè°ƒç”¨ä¼‘çœ ç³»ç»Ÿè°ƒç”¨çš„é—´éš™ï¼Œé”å¯èƒ½è¢«é‡Šæ”¾ï¼Œå”¤é†’ä¿¡å·åœ¨æ­¤é—´éš™å‘ç”Ÿ
- â€‹**åæœ**â€‹ï¼šæ°¸ä¹…æ€§ä¼‘çœ ï¼ˆä¿¡å·ä¸¢å¤±ï¼‰æˆ–æ— é™å»¶è¿Ÿå”¤é†’

â€‹**futex è§£å†³æ–¹æ¡ˆï¼šâ€‹**â€‹

```c
// å†…æ ¸ä¿è¯çš„åŸå­æ£€æŸ¥+é˜»å¡
if (*(futex_word) == expected_val) {
    add_to_wait_queue();
    schedule(); // åªæœ‰å€¼åŒ¹é…æ‰é˜»å¡
}
```

å†…æ ¸åœ¨**å•æ¬¡ç³»ç»Ÿè°ƒç”¨**ä¸­å®Œæˆ"æ£€æŸ¥å€¼+é˜»å¡"ï¼Œæ¶ˆé™¤äº†æ—¶é—´çª—é£é™©

å½“ Linus Torvalds è®¾è®¡ futex æ—¶è¯´ï¼š

> "The futex is designed to be a building block for user-space locking - small, fast, and primitive."

å®ƒæœ¬è´¨ä¸Šæ˜¯å°†ç”¨æˆ·æ€çš„å¹¶å‘æ„å›¾â€‹ï¼ˆæ£€æŸ¥ä»€ä¹ˆå€¼ï¼Ÿå¦‚ä½•é˜»å¡ï¼Ÿï¼‰ä¸å†…æ ¸æ€çš„å®ç°èƒ½åŠ›â€‹ï¼ˆå¦‚ä½•å®‰å…¨é˜»å¡ï¼Ÿæ€ä¹ˆå”¤é†’ï¼Ÿï¼‰é€šè¿‡æœ€å°æ¥å£è¿æ¥ï¼Œè¿™æ­£æ˜¯å…¶ç²¾å¦™ä¹‹å¤„â€”â€”ä¸åƒä¼ ç»Ÿç³»ç»Ÿè°ƒç”¨é‚£æ ·åšå…¨éƒ¨å·¥ä½œï¼Œä¹Ÿä¸åƒçº¯ç”¨æˆ·æ€é‚£æ ·æ— æ³•æ­£ç¡®å®ç°ã€‚

è¿™å°±æ˜¯ä¸ºä»€ä¹ˆ30å¹´åï¼Œfutex ä¾ç„¶æ˜¯ Linux åŒæ­¥åŸè¯­çš„åŸºçŸ³ï¼šå®ƒæ‰¾åˆ°äº†ç”¨æˆ·æ€çµæ´»æ€§å†…æ ¸æ€èƒ½åŠ›çš„æœ€ä½³å¹³è¡¡ç‚¹ã€‚

## 3. ä¸åŒè¯»å†™é”å®ç°æ¢ç´¢

### 3.1 std::shared_mutex(gcc)

[source code](https://github.com/gcc-mirror/gcc/blob/master/libstdc%2B%2B-v3/include/std/shared_mutex#L416-L447)

åœ¨ä¸æ”¯æŒ pthread_rwlock çš„å¹³å°ä¸‹å®ç°å¦‚ä¸‹ï¼ˆä¸ç›®å‰çš„ clang å®ç°ä¸€æ ·ï¼Œä½†å¯è¯»æ€§æ›´å¥½ï¼ˆä½è¿ç®—æ›´å°‘ï¼‰ï¼‰ï¼š

```cpp
 /// A shared mutex type implemented using std::condition_variable.
  class __shared_mutex_cv
  {
    friend class shared_timed_mutex;

    // Based on Howard Hinnant's reference implementation from N2406.

    // The high bit of _M_state is the write-entered flag which is set to
    // indicate a writer has taken the lock or is queuing to take the lock.
    // The remaining bits are the count of reader locks.
    //
    // To take a reader lock, block on gate1 while the write-entered flag is
    // set or the maximum number of reader locks is held, then increment the
    // reader lock count.
    // To release, decrement the count, then if the write-entered flag is set
    // and the count is zero then signal gate2 to wake a queued writer,
    // otherwise if the maximum number of reader locks was held signal gate1
    // to wake a reader.
    //
    // To take a writer lock, block on gate1 while the write-entered flag is
    // set, then set the write-entered flag to start queueing, then block on
    // gate2 while the number of reader locks is non-zero.
    // To release, unset the write-entered flag and signal gate1 to wake all
    // blocked readers and writers.
    //
    // This means that when no reader locks are held readers and writers get
    // equal priority. When one or more reader locks is held a writer gets
    // priority and no more reader locks can be taken while the writer is
    // queued.

    // Only locked when accessing _M_state or waiting on condition variables.
    mutex		_M_mut;
    // Used to block while write-entered is set or reader count at maximum.
    condition_variable	_M_gate1;
    // Used to block queued writers while reader count is non-zero.
    condition_variable	_M_gate2;
    // The write-entered flag and reader count.
    unsigned		_M_state;

    static constexpr unsigned _S_write_entered
      = 1U << (sizeof(unsigned)*__CHAR_BIT__ - 1);
    static constexpr unsigned _S_max_readers = ~_S_write_entered;

    // Test whether the write-entered flag is set. _M_mut must be locked.
    bool _M_write_entered() const { return _M_state & _S_write_entered; }

    // The number of reader locks currently held. _M_mut must be locked.
    unsigned _M_readers() const { return _M_state & _S_max_readers; }

  public:
    __shared_mutex_cv() : _M_state(0) {}

    ~__shared_mutex_cv()
    {
      __glibcxx_assert( _M_state == 0 );
    }

    __shared_mutex_cv(const __shared_mutex_cv&) = delete;
    __shared_mutex_cv& operator=(const __shared_mutex_cv&) = delete;

    // Exclusive ownership

    void
    lock()
    {
      unique_lock<mutex> __lk(_M_mut);
      // Wait until we can set the write-entered flag.
      _M_gate1.wait(__lk, [this]{ return !_M_write_entered(); });
      _M_state |= _S_write_entered;
      // Then wait until there are no more readers.
      _M_gate2.wait(__lk, [this]{ return _M_readers() == 0; });
    }

    bool
    try_lock()
    {
      unique_lock<mutex> __lk(_M_mut, try_to_lock);
      if (__lk.owns_lock() && _M_state == 0)
	{
	  _M_state = _S_write_entered;
	  return true;
	}
      return false;
    }

    void
    unlock()
    {
      lock_guard<mutex> __lk(_M_mut);
      __glibcxx_assert( _M_write_entered() );
      _M_state = 0;
      // call notify_all() while mutex is held so that another thread can't
      // lock and unlock the mutex then destroy *this before we make the call.
      _M_gate1.notify_all();
    }

    // Shared ownership

    void
    lock_shared()
    {
      unique_lock<mutex> __lk(_M_mut);
      _M_gate1.wait(__lk, [this]{ return _M_state < _S_max_readers; });
      ++_M_state;
    }

    bool
    try_lock_shared()
    {
      unique_lock<mutex> __lk(_M_mut, try_to_lock);
      if (!__lk.owns_lock())
	return false;
      if (_M_state < _S_max_readers)
	{
	  ++_M_state;
	  return true;
	}
      return false;
    }

    void
    unlock_shared()
    {
      lock_guard<mutex> __lk(_M_mut);
      __glibcxx_assert( _M_readers() > 0 );
      auto __prev = _M_state--;
      if (_M_write_entered())
	{
	  // Wake the queued writer if there are no more readers.
	  if (_M_readers() == 0)
	    _M_gate2.notify_one();
	  // No need to notify gate1 because we give priority to the queued
	  // writer, and that writer will eventually notify gate1 after it
	  // clears the write-entered flag.
	}
      else
	{
	  // Wake any thread that was blocked on reader overflow.
	  if (__prev == _S_max_readers)
	    _M_gate1.notify_one();
	}
    }
  };
#endif
```

clangçš„ shared_mutexå°±æ˜¯ä¸Šè¿°å®ç°æ–¹å¼ï¼Œåªä¸è¿‡ gcc è¿˜å•ç‹¬å¯¹æ”¯æŒ pthread_rwlockçš„å¹³å°ä½¿ç”¨äº†å¦ä¸€å¥—å®ç°ã€‚

ä¸Šè¿°å®ç°æ–¹å¼ä¸‰ä¸ªå…³é”®ç‚¹ï¼š
1. ç”¨ unsigned çš„æœ€é«˜ä½è¡¨ç¤ºå½“å‰æ˜¯å¦æœ‰ writer æŠ¢å è¯»å†™é”ï¼Œå…¶ä»–ä½ä½è¡¨ç¤ºè¯»è€…çš„æ•°é‡ã€‚
2. ç”¨ gate1 å’Œ gate2 ä¸¤ä¸ª cv åˆ†åˆ«ç”¨æ¥ç­‰å¾…ç‹¬å çš„å†™ flag å’Œæ˜¯å¦æœ‰è¯»è€…ã€‚
3. å®ç°æ•´ä½“ä¸Šæ˜¯å†™è€…ä¼˜å…ˆï¼Œå…·ä½“è¡¨ç°åœ¨ lock åŠ¨ä½œé€šè¿‡ä¸¤ä¸ª cv æ¡ä»¶åˆ†å¼€ï¼Œunlock_sharedæ—¶ä¸€æ—¦æœ‰å†™è€…å­˜åœ¨ä¸”å½“å‰æ˜¯æœ€åä¸€ä¸ªè¯»è€…åˆ™ä¼šå”¤é†’å†™è€…ã€‚

### 3.2 clang::shared_mutex

clang çš„ shared_mutex å®ç°ç›®å‰å°±å’Œå‰é¢ `std::shared_mutex(gcc)` ä¸€èŠ‚åˆ†äº«çš„å®ç°ä¸€æ¨¡ä¸€æ ·ã€‚

å…·ä½“æºç é“¾æ¥ï¼š
[shared_mutex.h](https://github.com/llvm/llvm-project/blob/llvmorg-20.1.8/libcxx/include/shared_mutex#L156-L183)
[shared_mutex.cpp](https://github.com/llvm/llvm-project/blob/llvmorg-20.1.8/libcxx/src/shared_mutex.cpp)

clang ä¹Ÿåœ¨å°è¯•é›†æˆ pthread_rwlock çš„å®ç°ï¼š
https://github.com/llvm/llvm-project/pull/148046

### 3.3 DB::SharedMutex

ClickHouse çš„ SharedMutex æ˜¯ä¸€ä¸ªéå¸¸å¥½çš„ futex è¿ç”¨çš„æ¡ˆä¾‹ï¼Œå› ä¸ºå…¶ä»£ç éå¸¸ç®€å•æ˜“æ‡‚ï¼Œç±»ä¼¼çš„å…¶ä»–è¿ç”¨ futex å®ç°çš„ SharedMutex è¿˜æœ‰ folly çš„å®ç°ï¼Œä½†æ˜¯é‚£ä¸ªä»£ç å®ç°ç›¸æ¯”ä¼šå¤æ‚å¾ˆå¤šï¼ˆç²—ç•¥çœ‹äº†ä¸‹ä¼¼ä¹è¿˜é€šè¿‡ slot å‡å°‘äº† CAS çš„æ¬¡æ•°ï¼‰ã€‚

æ‘˜å–å…³é”®ä»£ç å¦‚ä¸‹ï¼š
```cpp
    // Faster implementation of `std::shared_mutex` based on a pair of futexes
    class SharedMutex {
		...
        static constexpr uint64_t readers = (1ull << 32ull) - 1ull; // Lower 32 bits of state
        static constexpr uint64_t writers = ~readers; // Upper 32 bits of state

        alignas(64) std::atomic<uint64_t> state;
        std::atomic<uint32_t> waiters;
    };

namespace DB {
    namespace {
        inline int64_t futexWait(void *address, uint32_t value) {
            return syscall(SYS_futex, address, FUTEX_WAIT_PRIVATE, value, nullptr, nullptr, 0);
        }

        inline int64_t futexWake(void *address, int count) {
            return syscall(SYS_futex, address, FUTEX_WAKE_PRIVATE, count, nullptr, nullptr, 0);
        }

        inline constexpr uint32_t lowerHalf(uint64_t value) { return static_cast<uint32_t>(value & 0xffffffffull); }

        inline constexpr uint32_t upperHalf(uint64_t value) { return static_cast<uint32_t>(value >> 32ull); }


        inline uint32_t *upperHalfAddress(void *address) {
            return reinterpret_cast<uint32_t *>(address) + (std::endian::native == std::endian::little);
        }

        inline uint32_t *lowerHalfAddress(void *address) {
            return reinterpret_cast<uint32_t *>(address) + (std::endian::native == std::endian::big);
        }

        inline void futexWaitUpperFetch(std::atomic<uint64_t> &address, uint64_t &value) {
            futexWait(upperHalfAddress(&address), upperHalf(value));
            value = address.load();
        }

        inline void futexWaitLowerFetch(std::atomic<uint64_t> &address, uint64_t &value) {
            futexWait(lowerHalfAddress(&address), lowerHalf(value));
            value = address.load();
        }

        inline void futexWakeUpperAll(std::atomic<uint64_t> &address) {
            futexWake(upperHalfAddress(&address), INT_MAX);
        }

        inline void futexWakeLowerOne(std::atomic<uint64_t> &address) { futexWake(lowerHalfAddress(&address), 1); }
    } // namespace

    SharedMutex::SharedMutex() : state(0), waiters(0) {}

    void SharedMutex::lock() {
        uint64_t value = state.load();
        while (true) {
            if (value & writers) {
                waiters++;
                futexWaitUpperFetch(state, value);
                waiters--;
            } else if (state.compare_exchange_strong(value, value | writers))
                break;
        }

        value |= writers;
        while (value & readers)
            futexWaitLowerFetch(state, value);
    }

    bool SharedMutex::try_lock() {
        uint64_t value = 0;
        return state.compare_exchange_strong(value, writers);
    }

    void SharedMutex::unlock() {
        state.store(0);
        if (waiters)
            futexWakeUpperAll(state);
    }

    void SharedMutex::lock_shared() {
        uint64_t value = state.load();
        while (true) {
            if (value & writers) {
                waiters++;
                futexWaitUpperFetch(state, value);
                waiters--;
            } else if (state.compare_exchange_strong(value, value + 1))
                break;
        }
    }

    bool SharedMutex::try_lock_shared() {
        uint64_t value = state.load();
        while (true) {
            if (value & writers)
                return false;
            if (state.compare_exchange_strong(value, value + 1))
                break;
            // Concurrent try_lock_shared() should not fail, so we have to retry CAS, but avoid blocking wait
        }
        return true;
    }

    void SharedMutex::unlock_shared() {
        uint64_t value = state.fetch_sub(1) - 1;
        if (value == writers)
            futexWakeLowerOne(state); // Wake writer
    }

}
```


#### 3.3.1 ğŸ“œÂ `state`Â å˜é‡çš„ä½å¸ƒå±€

```markdown
+-------------------------------+-------------------------------+
|         é«˜ 32 ä½ (63-32)       |         ä½ 32 ä½ (31-0)        |
+-------------------------------+-------------------------------+
|          Writers åŒºåŸŸ          |          Readers åŒºåŸŸ          |
+-------------------------------+-------------------------------+
```

- â€‹ **`Writers`Â åŒºåŸŸ**â€‹ (é«˜ 32 ä½)
    - â€‹**å…¨ç½® 1 (`0xFFFFFFFF`)â€‹**â€‹ï¼šè¡¨ç¤ºæœ‰å†™é”æ­£åœ¨æŒæœ‰æˆ–ç­‰å¾…ï¼ˆç‹¬å æ¨¡å¼ï¼‰
    - â€‹**å…¨ 0**â€‹ï¼šè¡¨ç¤ºæ— å†™é”ï¼ˆé€šè¿‡Â `writers = ~readers`Â è®¡ç®—ï¼Œå€¼ä¸ºÂ `0xFFFFFFFF00000000`ï¼‰
- â€‹ **`Readers`Â åŒºåŸŸ**â€‹ (ä½ 32 ä½)
    - â€‹**è®¡æ•°å€¼**â€‹ï¼šè®°å½•å½“å‰æŒæœ‰è¯»é”çš„æ•°é‡ï¼ˆå…±äº«æ¨¡å¼ï¼‰

è‡³äºè¿™é‡Œä¸ºä»€ä¹ˆä¸ç”¨ 1bit è¡¨ç¤ºæ˜¯å¦æœ‰å†™è€…ï¼Œæˆ‘çŒœåº”è¯¥æ˜¯æœ¬æ¥å°±éœ€è¦ 64 å­—èŠ‚å¯¹é½ç¼“å­˜è¡Œï¼Œé¿å…æµªè´¹è¿™éƒ¨åˆ†å­—èŠ‚å§ï¼ˆä¸ç„¶å¯ä»¥æ›´ç²¾ç®€çš„ç”¨ uint32_tï¼‰

#### 3.3.2 ğŸ”‘ å…³é”®å®ç°æœºåˆ¶

##### 1ï¸âƒ£ â€‹ **è°ƒç”¨ Futex å®Œæˆç­‰å¾…å”¤é†’**â€‹

```cpp
alignas(64) std::atomic<uint64_t> state;  // ç¡®ä¿ç¼“å­˜è¡Œå¯¹é½
std::atomic<uint32_t> waiters;             // é«˜åŒºåŸŸç­‰å¾…è€…è®¡æ•°
```

- â€‹**åˆ†ç¦»é«˜ä½ 32 ä½**â€‹ï¼šé€šè¿‡Â `futexWaitUpper()`Â å’ŒÂ `futexWaitLower()`Â åˆ†åˆ«ç­‰å¾…é«˜ä½ä½å˜åŒ–
- â€‹**å”¤é†’ä¼˜åŒ–**â€‹ï¼š
    - `unlock()`Â â†’ å”¤é†’Â _æ‰€æœ‰_Â é«˜åŒºåŸŸç­‰å¾…è€…ï¼ˆ`futexWakeUpperAll()`ï¼‰
    - `unlock_shared()`Â â†’ å”¤é†’Â _ä¸€ä¸ª_Â ä½åŒºåŸŸç­‰å¾…è€…ï¼ˆ`futexWakeLowerOne()`ï¼‰

##### 2ï¸âƒ£ â€‹**å†™é”è·å– (`lock()`)â€‹**â€‹

```cpp
while (true) {
  if (value & writers) {  // ğŸ”’ å·²æœ‰å†™é”
    waiters++;            // æ³¨å†Œä¸ºé«˜åŒºåŸŸç­‰å¾…è€…
    futexWaitUpperFetch(state, value); // é˜»å¡
    waiters--;
  } 
  else if (CAS(value, value | writers)) break; // âœ… æˆåŠŸè®¾ç½®å†™é”æ ‡å¿—
}
while (value & readers) {  // ç­‰å¾…æ‰€æœ‰è¯»é”é‡Šæ”¾
  futexWaitLowerFetch(state, value);
}
```

- â€‹**ä¸¤æ­¥è·å–**â€‹ï¼š
    1. CAS è®¾ç½®é«˜ 32 ä½ä¸ºå…¨ 1ï¼ˆé˜»å¡æ–°è¯»è€…/å†™è€…ï¼‰
    2. å¾ªç¯ç­‰å¾…ä½ 32 ä½å½’é›¶ï¼ˆç°æœ‰è¯»è€…é‡Šæ”¾ï¼‰

##### 3ï¸âƒ£ â€‹**è¯»é”è·å– (`lock_shared()`)â€‹**â€‹

```cpp
while (true) {
  if (value & writers) {  // ğŸ”’ æœ‰å†™é”å­˜åœ¨
    waiters++; 
    futexWaitUpperFetch(state, value); // ç­‰å¾…å†™é”é‡Šæ”¾
    waiters--;
  } 
  else if (CAS(value, value + 1)) break; // âœ… è¯»è®¡æ•°+1
}
```

- â€‹**å†™é”ä¼˜å…ˆ**â€‹ï¼šæ£€æµ‹åˆ°é«˜åŒºåŸŸéé›¶æ—¶é˜»å¡ï¼ˆé¿å…å†™é”é¥¥é¥¿ï¼‰

##### 4ï¸âƒ£ â€‹**è§£é”ä¼˜åŒ–ç­–ç•¥**â€‹

| æ–¹æ³•                | è¡Œä¸º                                            |
| ----------------- | --------------------------------------------- |
| `unlock()`        | `state=0`Â + å”¤é†’æ‰€æœ‰é«˜åŒºåŸŸç­‰å¾…è€…ï¼ˆè¯»/å†™çº¿ç¨‹ï¼‰                 |
| `unlock_shared()` | è¯»è®¡æ•°å‡ 1ï¼Œè‹¥Â `value == writers`ï¼ˆå³è¯»å½’é›¶ä¸”å†™ç­‰å¾…ï¼‰â†’ å”¤é†’ä¸€ä¸ªå†™è€… |
è¿™ä¸ªæ€è·¯å’Œå‰é¢æåˆ°çš„ `shared_mutex` å®ç°æ˜¯ä¸€æ ·çš„ï¼ŒåŒæ ·çš„å†™è€…ä¼˜å…ˆï¼Œä½†ä½¿ç”¨äº† futex åšäº†æ€§èƒ½ä¼˜åŒ–ã€‚
##### 5ï¸âƒ£ â€‹**ç«¯åºå…¼å®¹å¤„ç†**â€‹

```cpp
inline uint32_t* upperHalfAddress(void* addr) {
  return reinterpret_cast<uint32_t*>(addr) + (std::endian::native == std::endian::little);
}
```

- è‡ªåŠ¨é€‚é…å¤§å°ç«¯æ¶æ„ï¼ˆä½åœ°å€å­˜æ”¾ä½/é«˜ä½ï¼‰
### 3.4 pthread_rwlock

[pthread_rwlock_common(glibc2.25)](https://elixir.bootlin.com/glibc/glibc-2.25/source/nptl/pthread_rwlock_common.c#L29-L214)
æœ‰å…³ [changelog](https://abi-laboratory.pro/?view=changelog&l=glibc&v=2.25) å¦‚ä¸‹ï¼š
```
* A new version of pthread_rwlock functions have been implemented to use a more
  scalable algorithm primarily through not using a critical section anymore to
  make state changes.
```

ä»¥ä¸‹ä¸ºæ³¨é‡Šä¸­çš„æœ‰å…³ pthread_rwlock çš„è®¾è®¡æè¿°ï¼Œå…¶ä¸­æœ‰æåˆ° pthread_rwlock æ”¯æŒæŒ‡å®šè¯»ä¼˜å…ˆæˆ–å†™ä¼˜å…ˆï¼Œè€Œé»˜è®¤æ˜¯è¯»ä¼˜å…ˆï¼ˆè¿™ä¹Ÿèƒ½è§£é‡Šå‰é¢çš„ benchmark ç»“æœäº†ï¼‰ï¼š
```
/* A reader--writer lock that fulfills the POSIX requirements (but operations
   on this lock are not necessarily full barriers, as one may interpret the   POSIX requirement about "synchronizing memory").  All critical sections are   in a total order, writers synchronize with prior writers and readers, and   readers synchronize with prior writers.
   A thread is allowed to acquire a read lock recursively (i.e., have rdlock   critical sections that overlap in sequenced-before) unless the kind of the   rwlock is set to PTHREAD_RWLOCK_PREFER_WRITERS_NONRECURSIVE_NP.
   This lock is built so that workloads of mostly readers can be executed with   low runtime overheads.  This matches that the default kind of the lock is   PTHREAD_RWLOCK_PREFER_READER_NP.  Acquiring a read lock requires a single   atomic addition if the lock is or was previously acquired by other   readers; releasing the lock is a single CAS if there are no concurrent   writers.   Workloads consisting of mostly writers are of secondary importance.   An uncontended write lock acquisition is as fast as for a normal   exclusive mutex but writer contention is somewhat more costly due to   keeping track of the exact number of writers.  If the rwlock kind requests   writers to be preferred (i.e., PTHREAD_RWLOCK_PREFER_WRITERS_NP or the   no-recursive-readers variant of it), then writer--to--writer lock ownership   hand-over is fairly fast and bypasses lock acquisition attempts by readers.   The costs of lock ownership transfer between readers and writers vary.  If   the program asserts that there are no recursive readers and writers are   preferred, then write lock acquisition attempts will block subsequent read   lock acquisition attempts, so that new incoming readers do not prolong a   phase in which readers have acquired the lock.
   The main components of the rwlock are a writer-only lock that allows only   one of the concurrent writers to be the primary writer, and a   single-writer-multiple-readers lock that decides between read phases, in   which readers have acquired the rwlock, and write phases in which a primary   writer or a sequence of different primary writers have acquired the rwlock.
   The single-writer-multiple-readers lock is the central piece of state   describing the rwlock and is encoded in the __readers field (see below for   a detailed explanation):
   State WP  WL  R   RW  Notes   ---------------------------   #1    0   0   0   0   Lock is idle (and in a read phase).   #2    0   0   >0  0   Readers have acquired the lock.   #3    0   1   0   0   Lock is not acquired; a writer is waiting for a write
			 phase to start or will try to start one.   #4    0   1   >0  0   Readers have acquired the lock; a writer is waiting
			 and explicit hand-over to the writer is required.   #4a   0   1   >0  1   Same as #4 except that there are further readers
			 waiting because the writer is to be preferred.   #5    1   0   0   0   Lock is idle (and in a write phase).   #6    1   0   >0  0   Write phase; readers are waiting for a read phase to
			 start or will try to start one.   #7    1   1   0   0   Lock is acquired by a writer.   #8    1   1   >0  0   Lock acquired by a writer and readers are waiting;
			 explicit hand-over to the readers is required.
   WP (PTHREAD_RWLOCK_WRPHASE) is true if the lock is in a write phase, so   potentially acquired by a primary writer.   WL (PTHREAD_RWLOCK_WRLOCKED) is true if there is a primary writer (i.e.,   the thread that was able to set this bit from false to true).   R (all bits in __readers except the number of least-significant bits   denoted in PTHREAD_RWLOCK_READER_SHIFT) is the number of readers that have   or are trying to acquired the lock.  There may be more readers waiting if   writers are preferred and there will be no recursive readers, in which   case RW (PTHREAD_RWLOCK_RWAITING) is true in state #4a.
   We want to block using futexes but using __readers as a futex word directly   is not a good solution.  First, we want to wait on different conditions   such as waiting for a phase change vs. waiting for the primary writer to   release the writer-only lock.  Second, the number of readers could change   frequently, which would make it likely that a writer's futex_wait fails   frequently too because the expected value does not match the value of   __readers anymore.   Therefore, we split out the futex words into the __wrphase_futex and   __writers_futex fields.  The former tracks the value of the WP bit and is   changed after changing WP by the thread that changes WP.  However, because   of the POSIX requirements regarding mutex/rwlock destruction (i.e., that   destroying a rwlock is allowed as soon as no thread has acquired or will   acquire the lock), we have to be careful and hand over lock ownership (via   a phase change) carefully to those threads waiting.  Specifically, we must   prevent a situation in which we are not quite sure whether we still have   to unblock another thread through a change to memory (executing a   futex_wake on a former futex word that is now used for something else is   fine).   The scheme we use for __wrphase_futex is that waiting threads that may   use the futex word to block now all have to use the futex word to block; it   is not allowed to take the short-cut and spin-wait on __readers because   then the waking thread cannot just make one final change to memory to   unblock all potentially waiting threads.  If, for example, a reader   increments R in states #7 or #8, it has to then block until __wrphase_futex   is 0 and it can confirm that the value of 0 was stored by the primary   writer; in turn, the primary writer has to change to a read phase too when   releasing WL (i.e., to state #2), and it must change __wrphase_futex to 0   as the next step.  This ensures that the waiting reader will not be able to   acquire, release, and then destroy the lock concurrently with the pending   futex unblock operations by the former primary writer.  This scheme is   called explicit hand-over in what follows.   Note that waiting threads can cancel waiting only if explicit hand-over has   not yet started (e.g., if __readers is still in states #7 or #8 in the   example above).
   Writers determine the primary writer through WL.  Blocking using futexes   is performed using __writers_futex as a futex word; primary writers will   enable waiting on this futex by setting it to 1 after they acquired the WL   bit and will disable waiting by setting it to 0 before they release WL.   This leaves small windows where blocking using futexes is not possible   although a primary writer exists, but in turn decreases complexity of the   writer--writer synchronization and does not affect correctness.   If writers are preferred, writers can hand over WL directly to other   waiting writers that registered by incrementing __writers:  If the primary   writer can CAS __writers from a non-zero value to the same value with the   PTHREAD_RWLOCK_WRHANDOVER bit set, it effectively transfers WL ownership   to one of the registered waiting writers and does not reset WL; in turn,   a registered writer that can clear PTHREAD_RWLOCK_WRHANDOVER using a CAS   then takes over WL.  Note that registered waiting writers can cancel   waiting by decrementing __writers, but the last writer to unregister must   become the primary writer if PTHREAD_RWLOCK_WRHANDOVER is set.   Also note that adding another state/bit to signal potential writer--writer   contention (e.g., as done in the normal mutex algorithm) would not be   helpful because we would have to conservatively assume that there is in   fact no other writer, and wake up readers too.
   To avoid having to call futex_wake when no thread uses __wrphase_futex or   __writers_futex, threads will set the PTHREAD_RWLOCK_FUTEX_USED bit in the   respective futex words before waiting on it (using a CAS so it will only be   set if in a state in which waiting would be possible).  In the case of   __writers_futex, we wake only one thread but several threads may share   PTHREAD_RWLOCK_FUTEX_USED, so we must assume that there are still others.   This is similar to what we do in pthread_mutex_lock.  We do not need to   do this for __wrphase_futex because there, we always wake all waiting   threads.
   Blocking in the state #4a simply uses __readers as futex word.  This   simplifies the algorithm but suffers from some of the drawbacks discussed   before, though not to the same extent because R can only decrease in this   state, so the number of potentially failing futex_wait attempts will be   bounded.  All threads moving from state #4a to another state must wake   up threads blocked on the __readers futex.
   The ordering invariants that we have to take care of in the implementation   are primarily those necessary for a reader--writer lock; this is rather   straightforward and happens during write/read phase switching (potentially   through explicit hand-over), and between writers through synchronization   involving the PTHREAD_RWLOCK_WRLOCKED or PTHREAD_RWLOCK_WRHANDOVER bits.   Additionally, we need to take care that modifications of __writers_futex   and __wrphase_futex (e.g., by otherwise unordered readers) take place in   the writer critical sections or read/write phases, respectively, and that   explicit hand-over observes stores from the previous phase.  How this is   done is explained in more detail in comments in the code.
   Many of the accesses to the futex words just need relaxed MO.  This is   possible because we essentially drive both the core rwlock synchronization   and the futex synchronization in parallel.  For example, an unlock will   unlock the rwlock and take part in the futex synchronization (using   PTHREAD_RWLOCK_FUTEX_USED, see above); even if they are not tightly   ordered in some way, the futex synchronization ensures that there are no   lost wake-ups, and woken threads will then eventually see the most recent   state of the rwlock.  IOW, waiting threads will always be woken up, while   not being able to wait using futexes (which can happen) is harmless; in   turn, this means that waiting threads don't need special ordering wrt.   waking threads.
   The futex synchronization consists of the three-state futex word:   (1) cannot block on it, (2) can block on it, and (3) there might be a   thread blocked on it (i.e., with PTHREAD_RWLOCK_FUTEX_USED set).   Relaxed-MO atomic read-modify-write operations are sufficient to maintain   this (e.g., using a CAS to go from (2) to (3) but not from (1) to (3)),   but we need ordering of the futex word modifications by the waking threads   so that they collectively make correct state changes between (1)-(3).   The futex-internal synchronization (i.e., the conceptual critical sections   around futex operations in the kernel) then ensures that even an   unconstrained load (i.e., relaxed MO) inside of futex_wait will not lead to   lost wake-ups because either the waiting thread will see the change from   (3) to (1) when a futex_wake came first, or this futex_wake will wake this   waiting thread because the waiting thread came first.
   POSIX allows but does not require rwlock acquisitions to be a cancellation   point.  We do not support cancellation.
   TODO We do not try to elide any read or write lock acquisitions currently.   While this would be possible, it is unclear whether HTM performance is   currently predictable enough and our runtime tuning is good enough at   deciding when to use elision so that enabling it would lead to consistently   better performance.  */
```


#### 3.4.1 æ€»ä½“è®¾è®¡æè¿°

ä½¿ç”¨ AI å¯¹æ•´ä½“è®¾è®¡æè¿°åšäº†æ€»ç»“ã€‚

è¯¥æ–‡ä»¶æ˜¯ â€‹**glibc åº“**ä¸­ POSIX è¯»å†™é”ï¼ˆreader-writer lockï¼‰çš„æ ¸å¿ƒå®ç°ä»£ç ã€‚è¯»å†™é”å…è®¸å¤šä¸ªçº¿ç¨‹åŒæ—¶è¯»å–å…±äº«èµ„æºï¼Œä½†å†™å…¥æ—¶éœ€è¦ç‹¬å è®¿é—®ï¼Œé€‚ç”¨äºè¯»å¤šå†™å°‘çš„åœºæ™¯ã€‚

---
##### æ ¸å¿ƒè®¾è®¡ç›®æ ‡

1. â€‹**POSIX å…¼å®¹æ€§**:
    - æ»¡è¶³ POSIX æ ‡å‡†å¯¹å†…å­˜åŒæ­¥çš„è¦æ±‚ï¼ˆä¸´ç•ŒåŒºæ“ä½œæ˜¯å†…å­˜å±éšœï¼‰ã€‚
    - æ‰€æœ‰ä¸´ç•ŒåŒºæ“ä½œ**å…¨åºåŒ–**â€‹ï¼šå†™æ“ä½œä¸ä¹‹å‰çš„å†™/è¯»æ“ä½œåŒæ­¥ï¼Œè¯»æ“ä½œä¸ä¹‹å‰çš„å†™æ“ä½œåŒæ­¥ã€‚
2. â€‹**æ€§èƒ½ä¼˜åŒ–**:
    - â€‹**è¯»ä¼˜å…ˆ**â€‹ï¼šé»˜è®¤æ¨¡å¼ï¼ˆ`PTHREAD_RWLOCK_PREFER_READER_NP`ï¼‰ä¸‹ï¼Œæ— ç«äº‰æ—¶ï¼š
        - â€‹**è·å–è¯»é”**â€‹ï¼šä»…éœ€ä¸€ä¸ªåŸå­åŠ æ³•æŒ‡ä»¤ã€‚
        - â€‹**é‡Šæ”¾è¯»é”**â€‹ï¼šè‹¥æ— ç§é”ï¼Œä»…éœ€ä¸€ä¸ª CAS æŒ‡ä»¤ã€‚
    - â€‹**å†™ä¼˜å…ˆ**â€‹ï¼ˆ`PTHREAD_RWLOCK_PREFER_WRITER_NP`ï¼‰ï¼š
        - å†™å…¥è€…å¯ç›´æ¥ç§»äº¤é”æ‰€æœ‰æƒï¼Œç»•è¿‡è¯»è¯·æ±‚ã€‚
        - é¿å…è¯»é”é€’å½’ï¼ˆé˜²æ­¢è¯»è€…é•¿æœŸå ç”¨é”ï¼‰ã€‚

---
##### æ ¸å¿ƒçŠ¶æ€æœºï¼ˆåŸºäºÂ `__readers`Â å­—æ®µï¼‰

è¯»å†™é”çŠ¶æ€é€šè¿‡ä½æ©ç Â `__readers`Â è¡¨ç¤ºï¼ŒåŒ…å«ä»¥ä¸‹æ ‡å¿—ä½ï¼š

- â€‹**WPï¼ˆå†™é˜¶æ®µæ ‡å¿—ï¼‰â€‹**â€‹ï¼š`PTHREAD_RWLOCK_WRPHASE`ï¼Œè¡¨ç¤ºå¤„äºå†™é˜¶æ®µã€‚
- â€‹**WLï¼ˆå†™é”æ ‡å¿—ï¼‰â€‹**â€‹ï¼š`PTHREAD_RWLOCK_WRLOCKED`ï¼Œè¡¨ç¤ºä¸»å†™è€…å·²å ç”¨é”ã€‚
- â€‹**Rï¼ˆè¯»è€…è®¡æ•°ï¼‰â€‹**â€‹ï¼šä½Â `PTHREAD_RWLOCK_READER_SHIFT`Â ä½ï¼Œè®°å½•æ´»è·ƒè¯»è€…æ•°ã€‚
- â€‹**RWï¼ˆè¯»è€…ç­‰å¾…æ ‡å¿—ï¼‰â€‹**â€‹ï¼š`PTHREAD_RWLOCK_RWAITING`ï¼Œè¡¨ç¤ºæœ‰è¯»è€…å› å†™ä¼˜å…ˆè€Œé˜»å¡ã€‚

###### çŠ¶æ€è¡¨

| çŠ¶æ€  | WP  | WL  | R   | RW  | æè¿°                    |
| --- | --- | --- | --- | --- | --------------------- |
| #1  | 0   | 0   | 0   | 0   | ç©ºé—²ï¼ˆè¯»é˜¶æ®µï¼‰               |
| #2  | 0   | 0   | >0  | 0   | è¯»è€…æŒæœ‰é”                 |
| #3  | 0   | 1   | 0   | 0   | ç©ºé—²ï¼ˆå†™è€…å¾…å¯åŠ¨å†™é˜¶æ®µï¼‰          |
| #4  | 0   | 1   | >0  | 0   | è¯»è€…æŒæœ‰é”ï¼Œå†™è€…ç­‰å¾…ï¼ˆéœ€æ˜¾å¼ç§»äº¤ï¼‰     |
| #4a | 0   | 1   | >0  | 1   | åŒ #4ï¼Œä¸”æ›´å¤šè¯»è€…åœ¨ç­‰å¾…ï¼ˆå†™ä¼˜å…ˆï¼‰    |
| #5  | 1   | 0   | 0   | 0   | ç©ºé—²ï¼ˆå†™é˜¶æ®µï¼‰               |
| #6  | 1   | 0   | >0  | 0   | å†™é˜¶æ®µç»“æŸï¼Œè¯»è€…å¾…å¯åŠ¨è¯»é˜¶æ®µï¼ˆéœ€æ˜¾å¼ç§»äº¤ï¼‰ |
| #7  | 1   | 1   | 0   | 0   | å†™è€…æŒæœ‰é”                 |
| #8  | 1   | 1   | >0  | 0   | å†™è€…æŒæœ‰é”ï¼Œè¯»è€…ç­‰å¾…ï¼ˆéœ€æ˜¾å¼ç§»äº¤ï¼‰     |

###### å…³é”®çŠ¶æ€è½¬ç§»

- â€‹**æ˜¾å¼ç§»äº¤ï¼ˆExplicit Hand-Overï¼‰â€‹**â€‹ï¼š
    - çŠ¶æ€ #4 â†’ #3ï¼šå†™è€…ä»è¯»è€…æ¥ç®¡é”æ—¶ï¼Œéœ€ç¡®ä¿æ‰€æœ‰è¯»è€…é€€å‡ºä¸´ç•ŒåŒºã€‚
    - çŠ¶æ€ #6 â†’ #2ï¼šå†™é˜¶æ®µç»“æŸï¼Œéœ€æ˜¾å¼ç§»äº¤æ‰€æœ‰ç­‰å¾…çš„è¯»è€…ã€‚
- â€‹**å†™è€…ä¼˜å…ˆä¼˜åŒ–**â€‹ï¼š
    - åœ¨çŠ¶æ€ #4aï¼ˆRW=1ï¼‰ï¼Œæ–°è¯»è€…è¢«é˜»å¡ä»¥ä¿è¯å†™è€…ä¼˜å…ˆè·å–é”ã€‚

---


##### Futex åŒæ­¥æœºåˆ¶

ä¸ºè§£å†³é˜»å¡ç­‰å¾…é—®é¢˜ï¼Œä½¿ç”¨ä¸¤ä¸ªç‹¬ç«‹çš„ Futex å˜é‡ï¼š

1. â€‹ **`__wrphase_futex`**â€‹ï¼š
    - è·Ÿè¸ª â€‹**WP ä½**â€‹ çš„å˜æ›´ã€‚
    - ç¡®ä¿é”é”€æ¯æ—¶æ‰€æœ‰ç­‰å¾…çº¿ç¨‹æ­£ç¡®å”¤é†’ã€‚
    - â€‹**æ˜¾å¼ç§»äº¤è¦æ±‚**â€‹ï¼šè¯»è€…éœ€é˜»å¡è‡³Â `__wrphase_futex=0`ï¼ˆå†™è€…ç¡®è®¤é˜¶æ®µåˆ‡æ¢ï¼‰ã€‚
2. â€‹ **`__writers_futex`**â€‹ï¼š
    - ä¸»å†™è€…è·å–é”åè®¾ä¸ºÂ `1`ï¼Œé‡Šæ”¾å‰è®¾ä¸ºÂ `0`ã€‚
    - â€‹**å†™è€…é—´ç§»äº¤**â€‹ï¼šé€šè¿‡Â `PTHREAD_RWLOCK_WRHANDOVER`Â ä½ç›´æ¥ç§»äº¤é”æ‰€æœ‰æƒã€‚

###### ä¼˜åŒ–ï¼šé¿å…æ— æ•ˆ Futex è°ƒç”¨

- è®¾ç½®Â `PTHREAD_RWLOCK_FUTEX_USED`Â ä½ï¼š
    - çº¿ç¨‹ç­‰å¾…å‰æ ‡è®°å¯¹åº” Futex ä¸ºâ€œå¯èƒ½è¢«ä½¿ç”¨â€ã€‚
    - å”¤é†’æ—¶ä»…å½“æ ‡è®°å­˜åœ¨æ‰è§¦å‘Â `futex_wake`ã€‚

---

##### å†…å­˜é¡ºåºï¼ˆMemory Orderingï¼‰
- â€‹**æ ¸å¿ƒåŸåˆ™**â€‹ï¼šFutex åŒæ­¥ä¸é”çŠ¶æ€å˜æ›´å¹¶è¡Œæ‰§è¡Œã€‚
- â€‹**å®½æ¾å†…å­˜åºï¼ˆRelaxed MOï¼‰â€‹**â€‹ï¼š
    - Futex å˜é‡çš„è¯»å†™å¤šæ•°ä½¿ç”¨ Relaxed MOã€‚
    - Futex æ“ä½œè‡ªèº«ä¿è¯ï¼šå”¤é†’çº¿ç¨‹æœ€ç»ˆçœ‹åˆ°æœ€æ–°é”çŠ¶æ€ã€‚
- â€‹**ä¸¥æ ¼å†…å­˜åºåœºæ™¯**â€‹ï¼š
    - æ˜¾å¼ç§»äº¤æ—¶éœ€ç¡®ä¿å‰é˜¶æ®µçš„å­˜å‚¨æ“ä½œå¯è§ã€‚
    - Futex çŠ¶æ€å˜æ›´åºåˆ—å¿…é¡»ä¸¥æ ¼æœ‰åºï¼ˆä¾‹å¦‚ï¼šä»â€œå¯ç­‰å¾…â€åˆ°â€œæ— ç­‰å¾…â€çš„è½¬æ¢ï¼‰ã€‚

---

##### å…¶ä»–è®¾è®¡è¦ç‚¹

1. â€‹**é€’å½’è¯»é”**â€‹ï¼š
    - é»˜è®¤å…è®¸ï¼ˆ`PTHREAD_RWLOCK_PREFER_READER_NP`ï¼‰ã€‚
    - è‹¥è®¾ä¸ºÂ `PTHREAD_RWLOCK_PREFER_WRITER_NONRECURSIVE_NP`Â åˆ™ç¦æ­¢ã€‚
2. â€‹**å–æ¶ˆç‚¹ï¼ˆCancellationï¼‰â€‹**â€‹ï¼š
    - â€‹**ä¸æ”¯æŒå–æ¶ˆ**â€‹ï¼šPOSIX å…è®¸ä½† glibc æœªå®ç°ã€‚
3. â€‹**ç¡¬ä»¶äº‹åŠ¡å†…å­˜ï¼ˆHTMï¼‰â€‹**â€‹ï¼š
    - â€‹**æœªå¯ç”¨**â€‹ï¼šå› æ€§èƒ½ä¸ç¡®å®šæ€§å’Œè°ƒä¼˜æˆæœ¬è¾ƒé«˜ã€‚
4. â€‹**çŠ¶æ€ #4a çš„ç‰¹æ®Šå¤„ç†**â€‹ï¼š
    - ç›´æ¥ä»¥Â `__readers`Â ä½œä¸º Futex å­—ã€‚
    - R å€¼å•è°ƒé€’å‡ â†’ å¤±è´¥çš„Â `futex_wait`Â æ¬¡æ•°æœ‰é™ã€‚

---

##### æœ¯è¯­è¡¨

| æœ¯è¯­                         | è§£é‡Š                                   |
| -------------------------- | ------------------------------------ |
| â€‹**CAS**â€‹                  | Compare-And-Swapï¼ˆåŸå­äº¤æ¢æ“ä½œï¼‰             |
| â€‹**Futex**â€‹                | Linux å¿«é€Ÿç”¨æˆ·æ€äº’æ–¥é”ï¼ˆFast Userspace Mutexï¼‰ |
| â€‹**æ˜¾å¼ç§»äº¤**â€‹                 | ç¡®ä¿æ‰€æœ‰ç­‰å¾…çº¿ç¨‹è¢«å”¤é†’çš„é”æ‰€æœ‰æƒè½¬ç§»                   |
| â€‹**ä¸»å†™è€…ï¼ˆPrimary Writerï¼‰â€‹**â€‹ | æŒæœ‰Â `WL`Â ä½çš„ç‹¬å å†™å…¥è€…                      |
| â€‹**å†™é˜¶æ®µï¼ˆWrite Phaseï¼‰â€‹**â€‹    | é”å¤„äºå¯å†™å…¥çŠ¶æ€ï¼ˆ`WP=1`ï¼‰                     |

æ­¤å®ç°é€šè¿‡ç²¾ç»†çš„çŠ¶æ€æœºå’Œ Futex ä¼˜åŒ–ï¼Œåœ¨ä¿è¯ POSIX è¯­ä¹‰çš„åŒæ—¶ï¼Œæœ€å¤§é™åº¦æå‡äº†è¯»å¤šå†™å°‘åœºæ™¯çš„æ€§èƒ½ã€‚

#### 3.4.2 å¦‚ä½•å®ç°è¯»ä¼˜å…ˆå’Œå†™ä¼˜å…ˆ

ä»¥ä¸‹æ˜¯å¯¹ glibc è¯»å†™é”å®ç°ä¸­ã€Œå†™è€…ä¼˜å…ˆã€å’Œã€Œè¯»è€…ä¼˜å…ˆã€ç­–ç•¥æ ¸å¿ƒé€»è¾‘çš„ç®€åŒ–ä¼ªä»£ç ï¼Œèšç„¦ç­–ç•¥å®ç°çš„å…³é”®è·¯å¾„ï¼š

#####  â€‹**å†™è€…ä¼˜å…ˆç­–ç•¥å®ç°**â€‹ï¼ˆPTHREAD_RWLOCK_PREFER_WRITER_NONRECURSIVE_NPï¼‰

```c
// è¯»è€…è·å–é”
if (ç­–ç•¥ä¸ºå†™è€…ä¼˜å…ˆ && 
    å½“å‰å¤„äºè¯»é˜¶æ®µ && 
    æœ‰æ´»è·ƒå†™è€…(WRLOCKED) && 
    å·²æœ‰å…¶ä»–è¯»è€…) {
    è®¾ç½®RWAITINGæ ‡å¿— // è¡¨ç¤ºæ–°è¯»è€…éœ€ç­‰å¾…
    while (RWAITINGæ ‡å¿—å­˜åœ¨) {
        futex_wait(__readers) // é˜»å¡ç­‰å¾…å†™è€…å®Œæˆ
    }
}

// å†™è€…è·å–é”
if (æœ‰æ´»è·ƒå†™è€…(WRLOCKED)) {
    æ³¨å†Œä¸ºç­‰å¾…å†™è€…(__writers++)
    if (æ£€æµ‹åˆ°WRHANDOVERæ ‡å¿—) { // å†™è€…é—´ç›´æ¥ç§»äº¤
        è·å–WRLOCKEDæ‰€æœ‰æƒ
        æ— éœ€åˆ‡æ¢é˜¶æ®µ
    } else {
        futex_wait(__writers_futex) // ç­‰å¾…å†™è€…ç§»äº¤
    }
}

// å†™è€…é‡Šæ”¾é”
if (æœ‰ç­‰å¾…å†™è€…(__writers > 0)) {
    è®¾ç½®WRHANDOVERæ ‡å¿— // æŒ‡ç¤ºç§»äº¤æ‰€æœ‰æƒ
    ä¿æŒWRLOCKEDå’ŒWRPHASEä¸å˜
    futex_wake(__writers_futex) // å”¤é†’ä¸€ä¸ªå†™è€…
}
```

#####  â€‹**è¯»è€…ä¼˜å…ˆç­–ç•¥å®ç°**â€‹ï¼ˆPTHREAD_RWLOCK_PREFER_READER_NPï¼‰

```c
// è¯»è€…è·å–é”
ç›´æ¥å¢åŠ è¯»è€…è®¡æ•°
if (å¤„äºå†™é˜¶æ®µ) {
    futex_wait(__wrphase_futex) // ç­‰å¾…å†™é˜¶æ®µç»“æŸ
}

// å†™è€…è·å–é”
if (è¯»è€…è®¡æ•° > 0) {
    while (__wrphase_futex != 0) { 
        futex_wait(__wrphase_futex) // ç­‰å¾…æ˜¾å¼ç§»äº¤
    }
}

// æœ€åä¸€ä¸ªè¯»è€…é‡Šæ”¾é”
if (æœ‰ç­‰å¾…å†™è€…) {
    è®¾ç½®WRPHASEæ ‡å¿—        // å¯åŠ¨å†™é˜¶æ®µ
    __wrphase_futex = 1    // é€šçŸ¥å†™è€…å¯æ‰§è¡Œ
    futex_wake(__wrphase_futex) // å”¤é†’æ‰€æœ‰å†™è€…
}
```

##### â€‹**å…³é”®ç§»äº¤æœºåˆ¶**â€‹ï¼ˆä¸¤è€…é€šç”¨ï¼‰

```c
// æ˜¾å¼é˜¶æ®µç§»äº¤åè®®
å½“é”éœ€è¦åˆ‡æ¢é˜¶æ®µæ—¶ï¼ˆè¯»â†”å†™ï¼‰ï¼š
1. ä¿®æ”¹__readersçŠ¶æ€å­—
2. æ›´æ–°é˜¶æ®µæ ‡è®°ï¼š
   - è¯»â†’å†™: __wrphase_futex = 1
   - å†™â†’è¯»: __wrphase_futex = 0
3. è‹¥æ£€æµ‹åˆ°ç­‰å¾…çº¿ç¨‹(FUTEX_USED):
   futex_wake(æ‰€æœ‰ç›¸å…³ç­‰å¾…è€…)
```

##### ç­–ç•¥å¯¹æ¯”æ‘˜è¦

| â€‹**æ“ä½œ**â€‹   | â€‹**å†™è€…ä¼˜å…ˆç­–ç•¥**â€‹         | â€‹**è¯»è€…ä¼˜å…ˆç­–ç•¥**â€‹  |
| ---------- | -------------------- | ------------- |
| â€‹**æ–°è¯»è€…**â€‹  | å¯èƒ½è¢«RWAITINGé˜»å¡        | ç›´æ¥è·å–é”         |
| â€‹**æ–°å†™è€…**â€‹  | é€šè¿‡WRHANDOVERå¿«é€Ÿç§»äº¤     | ä¸¥æ ¼ç­‰å¾…å½“å‰è¯»è€…é‡Šæ”¾    |
| â€‹**è¯»è€…é‡Šæ”¾**â€‹ | æœ€åä¸€ä¸ªè¯»è€…è§¦å‘å†™é˜¶æ®µç§»äº¤        | ä»…å½“æ— è¯»è€…æ—¶æ‰å¯å¯åŠ¨å†™é˜¶æ®µ |
| â€‹**å†™è€…é‡Šæ”¾**â€‹ | ä¼˜å…ˆç§»äº¤å…¶ä»–å†™è€…(WRHANDOVER) | ç›´æ¥å”¤é†’æ‰€æœ‰ç­‰å¾…è¯»è€…    |

è¿™ç§è®¾è®¡çš„æ ¸å¿ƒåœ¨äºï¼š

1. â€‹**åŒé‡é˜¶æ®µæ ‡è®°**â€‹ï¼šé€šè¿‡`WRPHASE`çŠ¶æ€ä½å’Œ`__wrphase_futex`å˜é‡åˆ†ç¦»é”çŠ¶æ€åŒæ­¥ä¸çº¿ç¨‹å”¤é†’
2. â€‹**é«˜æ•ˆç§»äº¤æœºåˆ¶**â€‹ï¼š
    - å†™è€…ä¼˜å…ˆï¼šé€šè¿‡`WRHANDOVER`ä½ç›´æ¥ä¼ é€’å†™é”æ‰€æœ‰æƒ
    - è¯»è€…ä¼˜å…ˆï¼šé€šè¿‡æœ€åä¸€ä¸ªè¯»è€…çš„æ˜¾å¼é˜¶æ®µåˆ‡æ¢
3. â€‹**ç­‰å¾…ä¼˜åŒ–**â€‹ï¼š
    - `RWAITING`é¿å…å†™è€…ä¼˜å…ˆæ—¶çš„è¯»è€…å †ç§¯
    - `FUTEX_USED`é¿å…æ— æ•ˆçš„futexå”¤é†’

è¿™ç§å®ç°èƒ½åœ¨ä¸åŒç­–ç•¥ä¸‹ä¿æŒO(1)çš„æ— ç«äº‰è·¯å¾„æ€§èƒ½ï¼ŒåŒæ—¶é€šè¿‡æ˜¾å¼ç§»äº¤åè®®ä¿è¯ç­–ç•¥æ‰§è¡Œçš„ä¸¥æ ¼æ€§ã€‚
